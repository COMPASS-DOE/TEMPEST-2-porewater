---
title: "TMP Porewater Processing Markdown"
author: "AMP"
date: "`r Sys.Date()`"
output: html_document
---

This script imports raw data for NPOC and TDN measured using a Shimadzu TOC-L at PNNL MCRL and exports clean, Level 1 QC'ed data. Raw Data are read in from GitHub

Created: 2022-01-15 by Peter Regier for EXCHANGE
Updated: 2022-06-26 by Allison Myers-Pigg for TEMPEST
Updated and adapted for markdown: 2024-02-10 by Allison Myers-Pigg for TEMPEST 2.0
Updated and adapted for source waters: 2024-04-29 by AMP

# Set Up 
```{r setup, include=FALSE}
# load packages
require(pacman)
pacman::p_load(tidyverse, # keep things tidy
               janitor, # useful for simplifying column names
               googlesheets4, # read_sheet 
               googledrive, # drive_ functions
               plotrix,
               here) 

#double check your wd. should be ../tempest-system-level-analysis
#if not you need to do new relative file pathing
#this is where the TEMPEST DOC data is currently stored. Subject to reorg. 

getwd()

## Set Github filepath for NPOC raw data files:

directory= file.path(here() %>% dirname(), 'tempest-system-level-analysis/data/raw/DOC')

```

# Functions

```{r functions, include=FALSE}
## Create a function to read in data
read_data <- function(data){
  # First, scrape date from filename
  rundate <- str_extract(data, "[0-9]{8}")
  # Second, read in data
  read_delim(file = data, skip = 10, delim = "\t") %>% 
    rename(sample_name = `Sample Name`, 
           npoc_raw = `Result(NPOC)`, 
           tdn_raw = `Result(TN)`,
           run_datetime = `Date / Time`) %>% 
    select(sample_name, npoc_raw, tdn_raw,run_datetime) %>% 
    mutate(rundate = rundate)
}

read_mes <- function(readme){
  # First, scrape date from filename
  rundate <- str_extract(readme, "[0-9]{8}")
  # Second, read in Read Me
  readxl::read_excel(path = readme, sheet = 1) %>% 
    rename(sample_name = `Sample Name`,
           sample_vol = `Sample wt`,
           total_vol = `Total vol:`) %>% 
    select(sample_name, Action, sample_vol, total_vol) %>% 
    mutate(rundate = rundate)
}
```

# Set Up Date Ranges

```{r figure out files to use,include=TRUE}
files <- list.files(path = here::here(directory), pattern = "Summary", full.names = TRUE) 
ReadMes <- list.files(path = here::here(directory), pattern = "Readme", full.names = TRUE) 

files

```
Set the event (NEED TO MAKE SURE THIS IS RIGHT!!!)
```{r event and study dates}
endstudydate = lubridate::as_date("2024-01-31")
startstudydate = lubridate::as_date("2023-05-31")
  
WaterDeliveryStart1 = as.POSIXct("2023-06-06 05:30:00", tz = "EST")
WaterDeliveryStop1 = as.POSIXct("2023-06-06 14:30:00", tz = "EST")

WaterDeliveryStart2 = as.POSIXct("2023-06-07 05:30:00", tz = "EST")
WaterDeliveryStop2 = as.POSIXct("2023-06-07 14:30:00", tz = "EST")
```

```{r source water metadata}
source_water_dates_2022 <- readxl::read_excel("../TEMPEST-1-porewater/sample lists/Source_Water_Metadata_Jun2022_Event.xlsx") %>%
  rename(sample_name = `Label Name`) %>%
  select(sample_name, Date, Time) %>%
  mutate(Time = lubridate::force_tz(Time, "America/New_York"),
         Time = format(Time, format= "%H:%M:%S"),
  Timepoint = stringr::str_extract(sample_name,"HR\\d+"),
  Plot = case_when(stringr::str_detect(sample_name, 'FW') ~ "FW",
                   stringr::str_detect(sample_name, 'SW') ~ "SW",
  TRUE ~ NA)) %>%
  select(-sample_name)
  
```


# Import Data
```{r import data, include= TRUE}

npoc_raw <- files %>% 
  map_df(read_data) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
  bind_rows() 

blanks_raw <- files %>% 
  map_df(read_data) %>% 
  filter(grepl("^Blank", sample_name)) %>% # filter to blanks only
  bind_rows() 

readmes_dilution_action <- ReadMes %>% 
  map_df(read_mes) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
  filter(grepl("ilution correction", Action)) %>%
  bind_rows() 

readmes_all <- ReadMes %>% 
  map_df(read_mes) %>% 
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
  bind_rows() 

curvepts <-files %>% 
  map_df(read_data) %>% 
  filter(grepl("STD_", sample_name)) %>% # filter to curves only
  rename(standard_high_C = npoc_raw,
         standard_high_N = tdn_raw) %>%
  select(rundate,standard_high_C,standard_high_N) %>%
  pivot_longer(cols = c(standard_high_C,standard_high_N)) %>%
  na.omit() %>%
  group_by(rundate) %>%
  distinct()%>%
  pivot_wider(names_from= name, values_from = value)%>%
  bind_rows() 
```

# Calculate blanks and add to data

```{r blanks}
blanks <- blanks_raw %>% 
  filter(!run_datetime %in% NA) %>% 
  mutate(npoc_raw = ifelse(npoc_raw > 0, npoc_raw, NA)) %>%
  mutate(tdn_raw = ifelse(tdn_raw > 0, tdn_raw, NA)) %>%
  group_by(rundate) %>% 
  summarize(npoc_blank= round(mean(npoc_raw[!is.na(npoc_raw)]), 2),
            npoc_blank_SD= round(sd(npoc_raw[!is.na(npoc_raw)]), 2), #add SD columns
            tdn_blank= round(mean(tdn_raw[!is.na(tdn_raw)]), 2),
            tdn_blank_SD= round(sd(tdn_raw[!is.na(tdn_raw)]), 2)) %>% #add SD columns
  select(rundate, npoc_blank, npoc_blank_SD, tdn_blank, tdn_blank_SD)

View(blanks) # Check out the blank data 
```

# Flag sketch data 

```{r flagging} 
npoc_flagged <- npoc_raw %>% 
  filter(grepl("SOURCE|ESTUARY|BARGE", sample_name)) %>%
  filter(grepl("TMP", sample_name)) %>% # filter to TMP samples only
  inner_join(blanks, by = "rundate") %>% 
  inner_join(curvepts, by= "rundate") %>%
  mutate(tdn_flag = case_when(tdn_raw > standard_high_N ~ "value above cal curve",
                              tdn_blank > 0.25*tdn_raw ~ "blank is ≥ 25% of sample value" # flagging if blank concentration is > 20% of the sample concentration 
                               ), 
         #most curves only to 50, those samples were not above it. making 100 for the August and September, which used 0-100
         npoc_flag = case_when(npoc_raw > standard_high_C ~ "value above cal curve",
                               npoc_blank > 0.25*npoc_raw ~ "blank is ≥ 25% of sample value" # flagging if blank concentration is > 20% of the sample concentration
                               )
         # npoc_raw = case_when(npoc_flag == "incorrect sample naming, cannot resolve" ~ NA,
         #                      TRUE ~ npoc_raw),
         # tdn_raw = case_when(tdn_flag == "incorrect sample naming, cannot resolve" ~ NA,
         #                     TRUE ~ tdn_raw)
  )
```

# Dilution Corrections & Flagging 

```{r dilutions}
dilutions = 
  readmes_dilution_action %>% 
  mutate(Dilution =  total_vol/sample_vol) %>% 
  dplyr::select(rundate, sample_name, Action, Dilution) %>% 
  force()

samples_to_dilution_corrected = 
  npoc_flagged %>%
  left_join(dilutions, by = c("sample_name", "rundate")) %>% 
  filter(grepl("ilution correction", Action)) %>%
  filter(!Action %in% "Omit") %>% 
  mutate(doc_mg_l= npoc_raw * Dilution, tdn_mg_l = tdn_raw * Dilution, # True concentration = diluted concentration * total vol / sample vol
         doc_mg_l = as.numeric(doc_mg_l), doc_mg_l = round(doc_mg_l, 2),
         tdn_mg_l= as.numeric(tdn_mg_l), tdn_mg_l= round(tdn_mg_l, 2)) %>%
  mutate(doc_mg_l = case_when(Dilution > 30 & npoc_flag == "blank is ≥ 25% of sample value" ~ NA,
                              TRUE ~ doc_mg_l), # removing values if high blanks and high dilution ratios, potentially large source of error. 
         npoc_flag = case_when(is.na(doc_mg_l) ~ "omitted for high dilution and blank values",
                               TRUE ~ npoc_flag),
         tdn_mg_l = case_when(Dilution > 30 & tdn_flag == "blank is ≥ 25% of sample value" ~ NA,
                              TRUE ~ tdn_mg_l),
         tdn_flag = case_when(is.na(tdn_mg_l) ~ "omitted for high dilution and blank values",
                              TRUE ~ tdn_flag)) # removing values if high blanks and high dilution ratios, potentially large source of error. 

all_samples_dilution_corrected =
  npoc_flagged %>%
  left_join(readmes_all, by = c("sample_name", "rundate")) %>% 
  mutate(doc_mg_l = npoc_raw, tdn_mg_l = tdn_raw) %>%
  filter(!grepl("ilution correction", Action)) %>% 
  filter(!Action %in% "Omit") %>%
  bind_rows(samples_to_dilution_corrected) %>%
  dplyr::select(sample_name, rundate, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag)%>%
  mutate(doc_mg_l = if_else(doc_mg_l < 0, "NA", as.character(doc_mg_l)),
         tdn_mg_l = if_else(tdn_mg_l < 0, "NA", as.character(tdn_mg_l)),
         doc_mg_l = as.numeric(doc_mg_l), doc_mg_l = round(doc_mg_l, 2),
         tdn_mg_l= as.numeric(tdn_mg_l), tdn_mg_l= round(tdn_mg_l, 2))

#Identify if any duplicates were run, this should return an empty data frame if not:#

duplicates <- all_samples_dilution_corrected %>% subset(duplicated(sample_name))

View(duplicates)


```
 
 
```{r run only if duplicates}
reps <- all_samples_dilution_corrected2  %>%
  group_by(sample_name) %>%
  filter(n() > 1) 

View(reps)

reps_names <- reps %>%
  select(sample_name) %>%
  unique() 

samples_dilution_corrected2_no_reps <- all_samples_dilution_corrected2 %>%
  filter(!sample_name %in% reps_names$sample_name)

#need to remove a rep if the following conditions are met:
# 1) Flag says "high blank" &
# 2) Values are > 20% apart 
# If second condition is met but the first is not met, need to flag with "Inconsistent reps"
# If they are close in value, regardless of condition for 1), can be confident that they look good. 

reps_clean <- reps %>%
  group_by(sample_name) %>%
  mutate(doc_mg_l_max = max(doc_mg_l),
         doc_mg_l_min = min(doc_mg_l),
         doc_mg_l_percerr = (doc_mg_l_max - doc_mg_l_min) / doc_mg_l_max,
         Keep_doc = case_when(doc_mg_l_percerr < .25 ~ TRUE),
         tdn_mg_l_max = max(tdn_mg_l),
         tdn_mg_l_min = min(tdn_mg_l),
         tdn_mg_l_percerr = (tdn_mg_l_max - tdn_mg_l_min) / tdn_mg_l_max,
         Keep_tdn = case_when(tdn_mg_l_percerr < .25 ~ TRUE),
         doc_mg_l = case_when(Keep_doc == TRUE ~ doc_mg_l,
                              FALSE ~ NA),
         tdn_mg_l = case_when(Keep_tdn == TRUE ~ tdn_mg_l,
                              FALSE ~ NA)) %>%
  select(sample_name, doc_mg_l, tdn_mg_l, npoc_flag, tdn_flag) %>%
  summarise(doc_mg_l = mean(doc_mg_l, na.rm = TRUE),
            tdn_mg_l = mean(tdn_mg_l, na.rm = TRUE)) %>%
  mutate(npoc_flag = case_when(doc_mg_l == 'NaN' ~ "replicates greater than 25% different"),
         tdn_flag = case_when(tdn_mg_l == 'NaN' ~ "replicates greater than 25% different"),
         date = stringr::str_extract(sample_name, "[0-9]{8}"))
#Need to merge those:
npoc_dups_merged <- samples_dilution_corrected2_no_reps %>% 
  bind_rows(reps_clean)
```

# Clean data 

```{r start cleaning}

## Flagging data
npoc_flags <- all_samples_dilution_corrected %>% 
  ## add flags 
  # Below blank 
  mutate(npoc_flag = case_when(doc_mg_l == 'NaN'& sample_name %in% reps_clean$sample_name ~ "replicates greater than 25% different",
                               sample_name %in% reps_clean$sample_name ~ "average value of multiple aliquots",
                               doc_mg_l == 'NaN' ~ "value below blank",
                               grepl("POOL", sample_name) ~ "pooled sample",
                               grepl("pool", sample_name) ~ "pooled sample",
                               grepl("value above cal curve",npoc_flag) ~ "value above cal curve",
                               TRUE ~ npoc_flag), 
         tdn_flag = case_when(tdn_mg_l == 'NaN'& sample_name %in% reps_clean$sample_name ~ "replicates greater than 25% different",
                              sample_name %in% reps_clean$sample_name ~ "average value of multiple aliquots",
                              tdn_mg_l == 'NaN' ~ "value below blank",
                              grepl("POOL", sample_name) ~ "pooled sample",
                              grepl("pool", sample_name) ~ "pooled sample",
                              grepl("value above cal curve",tdn_flag) ~ "value above cal curve",
                              TRUE ~ tdn_flag)) 


npoc_wflags_metadata <-  npoc_flags %>%
  mutate(sample_name = stringr::str_replace(sample_name,"_DOC",""),
         sample_name = stringr::str_replace(sample_name,"HR6","HR7"),
         Event = stringr::str_extract(sample_name, "TMP"),
         Plot = stringr::str_extract(sample_name, 'FW|SW|C|ESTUARY'), 
         Grid = stringr::str_extract(sample_name, "B4|C3|C6|D5|E3|F4|F6|H3|H6|I5|SOURCE|ESTUARY|POOL|WELL"),
         Timepoint = stringr::str_extract(sample_name,"HR\\d+"),
         sample_name = stringr::str_remove(sample_name,"(?<=[0-9]{8})_\\d{8}|(?<=[0-9]{8})-\\d{8}"),
         sample_name = stringr::str_remove(sample_name, "_FW\\d{2}|_SW\\d{2}"),
         doc_mg_l = case_when(doc_mg_l == "NaN" ~ NA,
                              TRUE ~ doc_mg_l),
         tdn_mg_l = case_when(tdn_mg_l == "NaN" ~ NA,
                              TRUE ~ tdn_mg_l)) %>%
  mutate(date= stringr::str_extract(sample_name, "[0-9]{8}"),
         time = stringr::str_extract(sample_name, "(?<=[0-9]{8}_)\\d{4}"),
         time = str_replace(time, '\\d+', function(m) str_pad(m, 6, pad = '0', side = ("right")))
         ) %>%
    full_join(source_water_dates_2022, by=c("Timepoint","Plot")) %>%
  mutate(date = case_when(is.na(date)~ "20220622",
                          TRUE ~ date),
         time = case_when(Timepoint == "HR4" ~ "110000" ,
                          Timepoint == "HR8" ~ "150000", 
                          TRUE ~ time)) %>%
  mutate(date = lubridate::as_date(date, format = "%Y%m%d"),
         time= strptime(time, format ="%H%M%S"),
         time = strftime(time, "%H:%M:%S")) %>%
  mutate(date = case_when(is.na(date) ~ Date,
                          TRUE ~ date),
          time = case_when(is.na(time) ~ Time,
                          TRUE ~ time)) %>%
  mutate(  Plot = case_when(Grid == "ESTUARY" ~ "ESTUARY",
                        TRUE ~ Plot))%>%
  select(-Date,-Time)

   
 # filter(!is.na(date))


source_npoc_wflags_metadata_summarized <- npoc_wflags_metadata %>%
  group_by(Plot, date) %>%
  filter(!npoc_flag %in% "omitted for high dilution and blank values") %>%
  filter(!tdn_flag %in% "omitted for high dilution and blank values") %>%
  summarise(n=n(),
            doc_mg_l_sd = round(sd(doc_mg_l, na.rm = TRUE), 2),
            doc_mg_l_se = round(std.error(doc_mg_l, na.rm=TRUE), 2),
            doc_mg_l = round(mean(doc_mg_l, na.rm = TRUE), 2),
            tdn_mg_l_sd = round(sd(tdn_mg_l, na.rm = TRUE), 2),
            tdn_mg_l_se = round(std.error(tdn_mg_l, na.rm=TRUE), 2),
            tdn_mg_l = round(mean(tdn_mg_l, na.rm = TRUE),2),
            date = min(date),
            .groups = "drop") 
  
```

# Write data

```{r write}

write_csv(npoc_wflags_metadata, "../TEMPEST-2-porewater/data/TMP_SOURCEWATER_NPOC_TDN_L1_2022_2023Events.csv")

write_csv(source_npoc_wflags_metadata_summarized , "../TEMPEST-2-porewater/data/TMP_SOURCEWATER_NPOC_TDN_L2_Summary_2022_2023Events.csv")
```

```{r quick plot}

npoc_wflags_metadata %>%
  group_by(Plot, Grid) %>%
  mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S")) %>%
  filter(date < startstudydate) %>%
ggplot()+
  geom_point(aes(x=datetime, y=doc_mg_l, color= Plot)) +
  theme_classic() +
  labs(x = "Date Time 2022", y = "DOC mgC/L", color = "Plot")

npoc_wflags_metadata %>%
  group_by(Plot, Grid) %>%
  mutate(datetime = as.POSIXct(paste(date, time), format = "%Y-%m-%d %H:%M:%S")) %>%
  filter(date > startstudydate) %>%
ggplot()+
  geom_point(aes(x=datetime, y=doc_mg_l, color= Plot)) +
  theme_classic() +
  labs(x = "Date Time 2023", y = "DOC mgC/L", color = "Plot")

```
